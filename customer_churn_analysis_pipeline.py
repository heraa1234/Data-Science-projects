# -*- coding: utf-8 -*-
"""Customer Churn Analysis Pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17l1mfna72C1JLbXCE8iNuVj6F6MsH9iB
"""

import pandas as pd
import numpy as np
from sqlalchemy import create_engine
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv("/content/WA_Fn-UseC_-Telco-Customer-Churn.csv")
df.head()

df.dtypes

df.isnull().sum()

df.drop(['customerID'], axis=1, inplace=True)

df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)

# Encode categorical variables
categorical_cols = df.select_dtypes(include=['object']).columns
df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

scaler = StandardScaler()
numerical_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']
df[numerical_cols] = scaler.fit_transform(df[numerical_cols])

# Step 3: Load - Export Cleaned Data
cleaned_data_path = "cleaned_telco_customer_churn.csv"
df.to_csv(cleaned_data_path, index=False)

engine = create_engine('sqlite:///telco_churn.db')
df.to_sql('customer_churn', con=engine, index=False, if_exists='replace')

# Step 4: Analysis - Basic Analysis and Visualization

# Churn Rate Calculation
churn_rate = df['Churn_Yes'].mean()
print(f"Overall Churn Rate: {churn_rate:.2%}")

# Correlation Analysis to understand feature importance
correlation = df.corr()['Churn_Yes'].sort_values(ascending=False)
print("\nTop factors affecting churn:\n", correlation.head(10))

# Visualization of Top Factors
top_factors = correlation.index[1:11]  # Exclude 'Churn_Yes' itself
plt.figure(figsize=(10, 6))
sns.barplot(x=correlation[top_factors], y=top_factors, palette='viridis')
plt.title("Top Correlated Factors with Churn")
plt.xlabel("Correlation Coefficient")
plt.ylabel("Feature")
plt.show()

# Splitting data for potential model training (e.g., classification model)
X = df.drop(['Churn_Yes'], axis=1)
y = df['Churn_Yes']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Export Train/Test data to CSV
X_train.to_csv("X_train.csv", index=False)
X_test.to_csv("X_test.csv", index=False)
y_train.to_csv("y_train.csv", index=False)
y_test.to_csv("y_test.csv", index=False)

print("\nData pipeline complete. Cleaned data saved to CSV and database.")

